{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b76bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\venvs\\mech_interp_py3pt13\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deca2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelA:\n",
    "    def __init__(self, model_name=\"facebook/opt-1.3b\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def generate(self, prompt, max_length=100):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(**inputs, max_length=max_length)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d040268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelB:\n",
    "    def __init__(self, model_name=\"tiiuae/falcon-rw-1b\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def generate(self, prompt, max_length=100):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(**inputs, max_length=max_length)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd746f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = ModelA()\n",
    "model_b = ModelB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0baa727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How do you build a car?\\nThe first step is to find a car that you like.\\nThe second step is to find a car that you can afford.\\nThe third step is to find a car that you can afford to fix.\\nThe fourth step is to find a car that you can afford to fix.\\nThe fifth step is to find a car that you can afford to fix.\\nThe sixth step is to find a car that you can afford to fix.\\nThe'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.generate(\"How do you build a car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86596ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "sequences = pipeline(\n",
    "   \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\",\n",
    "    max_length=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056bde9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech_interp_py3pt13",
   "language": "python",
   "name": "mech_interp_py3pt13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
